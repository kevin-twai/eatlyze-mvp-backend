#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªå‹•è£œç‡Ÿé¤Šå€¼å·¥å…· v3ï¼ˆæ•´åˆå°ç£ FDA é£Ÿå“è³‡æ–™åº«ï¼‰
--------------------------------------------------
å„ªå…ˆé †åºï¼š
  1ï¸âƒ£ NUTRITION_REF ç²¾æº–è£œå€¼
  2ï¸âƒ£ Ontology åˆ†é¡å¹³å‡è£œå€¼
  3ï¸âƒ£ é€£ç·šå°ç£é£Ÿè—¥ç½² FDA é£Ÿå“ç‡Ÿé¤Šæˆåˆ†é–‹æ”¾è³‡æ–™ API
  4ï¸âƒ£ è‡ªå‹•å‚™ä»½ CSVï¼Œæ”¯æ´å¿«å–é¿å…é‡è¤‡æŸ¥è©¢
"""

import csv
import json
import os
import requests
from datetime import datetime

CSV_PATH = "backend/app/data/foods_tw.csv"
ONTO_PATH = "backend/app/data/food_ontology.json"
CACHE_PATH = "backend/app/data/fda_cache.json"

FDA_API_URL = "https://data.fda.gov.tw/opendata/exportDataList.do?method=ExportDataList&InfoId=17"  # é£Ÿå“ç‡Ÿé¤Šæˆåˆ†è³‡æ–™é›†

# --------------------------------------------------
# ğŸ§  å…§å»ºç‡Ÿé¤Šåƒè€ƒè³‡æ–™ï¼ˆèˆ‡å‰ä¸€ç‰ˆç›¸åŒï¼‰
NUTRITION_REF = {
    "chicken breast": {"kcal": 165, "protein_g": 31, "fat_g": 3.6, "carb_g": 0},
    "beef steak": {"kcal": 250, "protein_g": 26, "fat_g": 17, "carb_g": 0},
    "salmon": {"kcal": 208, "protein_g": 20, "fat_g": 13, "carb_g": 0},
    "yellowback sea bream": {"kcal": 118, "protein_g": 20, "fat_g": 3, "carb_g": 0},
    "silken tofu": {"kcal": 55, "protein_g": 5, "fat_g": 3, "carb_g": 1},
    "firm tofu": {"kcal": 144, "protein_g": 15, "fat_g": 8, "carb_g": 2},
    "egg": {"kcal": 143, "protein_g": 13, "fat_g": 9.5, "carb_g": 0.7},
    "boiled egg": {"kcal": 155, "protein_g": 13, "fat_g": 11, "carb_g": 1},
    "century egg": {"kcal": 140, "protein_g": 12, "fat_g": 10, "carb_g": 1},
    "white rice": {"kcal": 130, "protein_g": 2.7, "fat_g": 0.3, "carb_g": 28},
    "broccoli": {"kcal": 34, "protein_g": 2.8, "fat_g": 0.4, "carb_g": 6.6},
    "soy sauce": {"kcal": 53, "protein_g": 8, "fat_g": 0, "carb_g": 5},
}

CATEGORY_AVG = {
    "é­šé¡": {"kcal": 150, "protein_g": 20, "fat_g": 8, "carb_g": 0},
    "è‚‰é¡": {"kcal": 230, "protein_g": 25, "fat_g": 15, "carb_g": 0},
    "è±†è£½å“": {"kcal": 100, "protein_g": 10, "fat_g": 6, "carb_g": 3},
    "è”¬èœ": {"kcal": 35, "protein_g": 2, "fat_g": 0.5, "carb_g": 6},
    "ä¸»é£Ÿ": {"kcal": 130, "protein_g": 3, "fat_g": 0.5, "carb_g": 28},
    "é†¬æ–™": {"kcal": 80, "protein_g": 2, "fat_g": 1, "carb_g": 10},
    "è›‹é¡": {"kcal": 150, "protein_g": 13, "fat_g": 10, "carb_g": 1},
}

# --------------------------------------------------
def norm(s: str) -> str:
    s = (s or "").strip().lower()
    for ch in (" ", "-", "_"):
        s = s.replace(ch, "")
    return s

def load_json(path):
    if not os.path.exists(path):
        return {}
    with open(path, "r", encoding="utf-8") as f:
        try:
            return json.load(f)
        except:
            return {}

def save_json(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def backup_csv(path):
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    bak = f"{path}.bak.{ts}"
    with open(path, "rb") as src, open(bak, "wb") as dst:
        dst.write(src.read())
    print(f"ğŸ§³ å·²å‚™ä»½ CSVï¼š{bak}")

def fetch_from_fda(keyword: str):
    """å‘¼å«å°ç£ FDA APIï¼Œå°‹æ‰¾æœ€æ¥è¿‘çš„é£Ÿæè³‡æ–™"""
    try:
        resp = requests.get(FDA_API_URL, timeout=15)
        if resp.status_code != 200:
            return None
        data = resp.text.splitlines()
        keyword = keyword.strip().lower()
        for line in data:
            if keyword in line.lower():
                cols = line.split(",")
                if len(cols) >= 6:
                    try:
                        kcal = float(cols[2])
                        protein = float(cols[3])
                        fat = float(cols[4])
                        carb = float(cols[5])
                        return {"kcal": kcal, "protein_g": protein, "fat_g": fat, "carb_g": carb}
                    except:
                        continue
        return None
    except Exception as e:
        print(f"[FDA] ç„¡æ³•å–å¾—è³‡æ–™: {e}")
        return None

def fill_values():
    cache = load_json(CACHE_PATH)
    ontology = load_json(ONTO_PATH)

    if not os.path.exists(CSV_PATH):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° CSVï¼š{CSV_PATH}")

    with open(CSV_PATH, "r", encoding="utf-8-sig", newline="") as f:
        reader = csv.DictReader(f)
        fieldnames = [h.lstrip("\ufeff") for h in reader.fieldnames]
        rows = [dict(r) for r in reader]

    ref_norm = {norm(k): v for k, v in NUTRITION_REF.items()}
    onto_norm = {norm(d.get("canonical", "")): d for d in ontology if isinstance(d, dict)}
    updated = 0

    for r in rows:
        key = norm(r.get("canonical", ""))
        if not key:
            continue
        def is_empty(x): return x in ("", None, "0", "0.0", 0, 0.0)

        ref = ref_norm.get(key)
        if not ref:
            onto = onto_norm.get(key)
            if onto:
                cat = onto.get("category")
                ref = CATEGORY_AVG.get(cat)

        if not ref:
            if key in cache:
                ref = cache[key]
            else:
                fda = fetch_from_fda(r.get("name", "") or r.get("canonical", ""))
                if fda:
                    cache[key] = fda
                    ref = fda
                    print(f"ğŸ” å¾ FDA å–å¾—è³‡æ–™: {r.get('canonical')} -> {fda}")

        if not ref:
            continue

        for k in ["kcal", "protein_g", "fat_g", "carb_g"]:
            if is_empty(r.get(k)):
                r[k] = str(ref[k])
                updated += 1

    if updated == 0:
        print("âœ… æ²’æœ‰éœ€è¦è£œå€¼çš„é …ç›®ã€‚")
        return

    backup_csv(CSV_PATH)
    with open(CSV_PATH, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)

    save_json(CACHE_PATH, cache)
    print(f"âœ… å·²æ›´æ–° {CSV_PATH}ï¼Œå…±è£œå…¥ {updated} å€‹æ¬„ä½ã€‚")
    print(f"ğŸ—ƒï¸ å¿«å–å·²åŒæ­¥åˆ° {CACHE_PATH}")

if __name__ == "__main__":
    fill_values()
